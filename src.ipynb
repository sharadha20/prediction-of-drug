{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "--tbNp282175"
      },
      "outputs": [],
      "source": [
        "import numpy as np #importing all the necessary library\n",
        "from sklearn.decomposition import PCA\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import KMeansSMOTE\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy import sparse\n",
        "from scipy. sparse import csr_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt \n",
        "from imblearn.over_sampling import ADASYN \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_datafile = \"trainingdata.txt\" #storing the training and test data files\n",
        "testing_datafile = \"testingdata.txt\""
      ],
      "metadata": {
        "id": "x3hZrSEI52fq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataloading(name_of_file, type_of_file): #function is defined to load the dataset\n",
        "    with open(name_of_file, \"r\") as read_file:#reading the dataset\n",
        "        nums = read_file.readlines()\n",
        "\n",
        "    if type_of_file == \"trainingdata\":\n",
        "        Training_labels = [int(l[0]) for l in nums] #converting to sparse data\n",
        "        for index, item in enumerate(Training_labels):\n",
        "            if (item == 0): \n",
        "                Training_labels[index] = -1\n",
        "        dfile = [re.sub(r'[^\\w]', ' ',l[1:]).split() for l in nums]\n",
        "\n",
        "    else:\n",
        "        Training_labels = []\n",
        "        dfile = [re.sub(r'[^\\w]', ' ',l).split() for l in nums]\n",
        "\n",
        "    Training_features = []\n",
        "\n",
        "    for f in dfile:\n",
        "      num = [0]*100001 #creating the list with size of the feature as 100001\n",
        "      for index, h in enumerate(f):\n",
        "        num[int(h)] = 1\n",
        "      Training_features.append(num)\n",
        "\n",
        "    return Training_features, Training_labels"
      ],
      "metadata": {
        "id": "-u5VDk1T52iS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Training_features, Training_labels = dataloading(training_datafile, \"trainingdata\") #loading the training data\n"
      ],
      "metadata": {
        "id": "iCVr6VMj6CO4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Truncated_SVD = TruncatedSVD(algorithm='randomized', n_components=500, n_iter=51, random_state=42) #using SVD for dimensionality reduction\n",
        "\n",
        "Truncated_SVDfitting = Truncated_SVD.fit(Training_features, Training_labels)\n",
        "reduced_Training_features = Truncated_SVDfitting.transform(Training_features)#the further reduced dimensions are stored\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XP9cvNRw6CRX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm_oversampler = SMOTE(random_state=42)#using smote to randomly increase the minority class which here is 1\n",
        "reduced_Training_features,Training_labels = sm_oversampler.fit_resample(reduced_Training_features,Training_labels)\n"
      ],
      "metadata": {
        "id": "-X4r-1uE6CTc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Testing_features, Testing_labels = dataloading(testing_datafile, \"test\")#loading the test dataset\n",
        "\n",
        "\n",
        "Testing_featuresReduced = Truncated_SVDfitting.transform(Testing_features)#reducing the features of test dataset\n"
      ],
      "metadata": {
        "id": "tti_LRNP52kx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nameofclassifier = [\"Decision Tree\",\"Bernoulli Naive Bayes\"]#defining the classifiers\n",
        "classifier_def =[DecisionTreeClassifier(random_state=42),BernoulliNB()]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tepVlp2Z6eE0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, val in zip(nameofclassifier, classifier_def):#using the classifier\n",
        "    print(name)\n",
        "    \n",
        "    crossval_calculation = cross_val_predict(val, reduced_Training_features, Training_labels, cv=10)#used for calculation of cross validation \n",
        "    print (metrics.classification_report(Training_labels, crossval_calculation))\n",
        "\n",
        "    tot_score = cross_val_score(val, reduced_Training_features, Training_labels)\n",
        "    \n",
        "    print ('\\nCross validation scores after performing the classification: ')\n",
        "    print (tot_score.mean())\n",
        "\n",
        "   \n",
        "    val.fit(reduced_Training_features, Training_labels)#the training dataset values are being trained\n",
        "\n",
        "    \n",
        "    predicted_results = val.predict(Testing_featuresReduced)#values are predicted for test dataset\n",
        "\n",
        "    \n",
        "\n",
        "    FinalOutputFile = 'format.txt' #final output is stored\n",
        "\n",
        "    print ('storing the output in', FinalOutputFile)\n",
        "\n",
        "    finaloutput = open(FinalOutputFile, 'w')#opening the file to write\n",
        "    for i in predicted_results:\n",
        "        if int(i) == -1:\n",
        "            i = 0\n",
        "        \n",
        "        finaloutput.write(str(i))\n",
        "        \n",
        "        finaloutput.write(\"\\n\")\n",
        "    \n",
        "    finaloutput.close() #closing the file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTugPWAH6m0u",
        "outputId": "d0feed2e-5a3f-470e-b6b5-c0c00da736b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.94      0.89      0.91       722\n",
            "           1       0.90      0.94      0.92       722\n",
            "\n",
            "    accuracy                           0.92      1444\n",
            "   macro avg       0.92      0.92      0.92      1444\n",
            "weighted avg       0.92      0.92      0.92      1444\n",
            "\n",
            "\n",
            "Cross validation scores after performing the classification: \n",
            "0.9009491541714725\n",
            "storing the output in format.txt\n",
            "Bernoulli Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.86      0.98      0.91       722\n",
            "           1       0.98      0.84      0.90       722\n",
            "\n",
            "    accuracy                           0.91      1444\n",
            "   macro avg       0.92      0.91      0.91      1444\n",
            "weighted avg       0.92      0.91      0.91      1444\n",
            "\n",
            "\n",
            "Cross validation scores after performing the classification: \n",
            "0.9058270857362551\n",
            "storing the output in format.txt\n"
          ]
        }
      ]
    }
  ]
}